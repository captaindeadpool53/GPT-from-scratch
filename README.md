# GPT from scratch
- Replicated GPT-1 architecture with scaled-down hyperparameters. 
- Uses a character level tokenization. 
- A Decoder only transformer is used.
- Self attention mechanism implemented from scratch.

Checkpoint for the trained model are present here and can be loaded through a cell in the notebook 
https://drive.google.com/file/d/1VS1Z5e2lCrJl4uhfzpy6Ay3J5H7EteSf/view?usp=sharing

This is done for learning purposes inspired by Andrej Karpathy's NanoGPT - https://youtu.be/kCc8FmEb1nY.
